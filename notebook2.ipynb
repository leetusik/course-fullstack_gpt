{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # Updated import\n",
    "# from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain.embeddings import CacheBackedEmbeddings\n",
    "# from langchain.document_loaders import TextLoader\n",
    "# from langchain.vectorstores import FAISS\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "# from langchain.storage import LocalFileStore\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     temperature=0.1,\n",
    "#     model_name=\"gpt-4o-mini\",\n",
    "# )\n",
    "\n",
    "# cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "# splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     separator=\"\\n\",\n",
    "#     chunk_size=600,\n",
    "#     chunk_overlap=100,\n",
    "# )\n",
    "# loader = TextLoader(\"./files/chapter_one.txt\")\n",
    "\n",
    "# docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "# vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "# retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "# map_doc_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"\"\"\n",
    "#             Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim. If there is no relevant text, return : ''\n",
    "#             -------\n",
    "#             {context}\n",
    "#             \"\"\",\n",
    "#         ),\n",
    "#         (\"human\", \"{question}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "\n",
    "# def map_docs(inputs):\n",
    "#     documents = inputs[\"documents\"]\n",
    "#     question = inputs[\"question\"]\n",
    "#     return \"\\n\\n\".join(\n",
    "#         map_doc_chain.invoke(\n",
    "#             {\"context\": doc.page_content, \"question\": question}\n",
    "#         ).content\n",
    "#         for doc in documents\n",
    "#     )\n",
    "\n",
    "\n",
    "# map_chain = {\n",
    "#     \"documents\": retriever,\n",
    "#     \"question\": RunnablePassthrough(),\n",
    "# } | RunnableLambda(map_docs)\n",
    "\n",
    "# final_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"\"\"\n",
    "#             Given the following extracted parts of a long document and a question, create a final answer. \n",
    "#             If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "#             ------\n",
    "#             {context}\n",
    "#             \"\"\",\n",
    "#         ),\n",
    "#         (\"human\", \"{question}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# chain = {\"context\": map_chain, \"question\": RunnablePassthrough()} | final_prompt | llm\n",
    "\n",
    "# chain.invoke(\"What do you know about Victory Mansion?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Winston lives in a place called Victory Mansions, which is described as grimy and situated in a landscape filled with rotting nineteenth-century houses. The buildings around him are shored up with timber, patched with cardboard, and have roofs made of corrugated iron. The area is marked by bombed sites, plaster dust swirling in the air, and overgrown with willow-herb, as well as sordid colonies of wooden dwellings resembling chicken-houses. Inside his flat, which is located seven flights up, there is a small kitchen with dark-colored bread and a bottle of colorless liquid labeled VICTORY GIN, and a living room with a small table and a telescreen. The overall atmosphere of his environment is bleak and oppressive, reflecting the totalitarian regime in which he lives.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 162, 'prompt_tokens': 524, 'total_tokens': 686, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None}, id='run-377284e3-a66f-4b08-a58d-2647ed9ad6b0-0', usage_metadata={'input_tokens': 524, 'output_tokens': 162, 'total_tokens': 686, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # Updated import\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "loader = TextLoader(\"./files/chapter_one.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim. If there is no relevant text, return : ''\n",
    "            -------\n",
    "            {context}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_docs(inputs):\n",
    "    documents = inputs[\"documents\"]\n",
    "    question = inputs[\"question\"]\n",
    "    return \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke(\n",
    "            {\"context\": doc.page_content, \"question\": question}\n",
    "        ).content\n",
    "        for doc in documents\n",
    "    )\n",
    "\n",
    "map_chain = {\"documents\": retriever, \"question\": RunnablePassthrough()} | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Given the following extracted parts of a long document and a question, create a final answer. If you don't know the answer, just say that you don't know. Don't try to make up an answer. \\n\\n {context}\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_chain = {\"question\": RunnablePassthrough(), \"context\": map_chain}| final_prompt | llm\n",
    "\n",
    "final_chain.invoke(\"Describe where Winston lives.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
